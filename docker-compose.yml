services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment: { ZOOKEEPER_CLIENT_PORT: 2181 }
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on: [zookeeper]
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports: ["9092:9092"]
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.3
    environment:
      discovery.type: single-node
      xpack.security.enabled: "false"
    ulimits: { memlock: { soft: -1, hard: -1 } }
    ports: ["9200:9200"]
  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.3
    environment: { ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]' }
    depends_on: [elasticsearch]
    ports: ["5601:5601"]
  airflow:
  image: apache/airflow:2.9.2
  environment:
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__WEBSERVER__RBAC: "True"
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "False"
    GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/gcp-sa.json
  volumes:
    - ./dags:/opt/airflow/dags
    - ./.env:/opt/airflow/.env
    - ./gcp-sa.json:/opt/airflow/gcp-sa.json:ro   # ⬅️ ajoute ceci
  command: standalone
  ports: ["8080:8080"]
  depends_on: [kafka]
